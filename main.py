#One-hot encoding (CountVectorizing)
#The most basic and naive method for transforming words into vectors is to count occurrence of each word in each document, isnâ€™t it? 
#Such an approach is called countvectorizing or one-hot encoding.

#The idea is to collect a set of documents (they can be words, sentences, paragraphs or even articles) and count the occurrence of every word in them.
#Strictly speaking, the columns of the resulting matrix are words and the rows are documents.

from sklearn.feature_extraction.text import CountVectorizer
# create CountVectorizer object
vectorizer = CountVectorizer()
corpus = [
          'Text of first document.',
          'Text of the second document made longer.',
          'Number three.',
          'This is number four.',
]
vectorizer = CountVectorizer()
# learn the vocabulary and store CountVectorizer sparse matrix in X
X = vectorizer.fit_transform(corpus)
print(vectorizer.get_feature_names())
# columns of X correspond to the result of this method
vectorizer.get_feature_names() == (
    ['document', 'first', 'four', 'is', 'longer',
     'made', 'number', 'of', 'second', 'text',
     'the', 'this', 'three'])
# retrieving the matrix in the numpy form
X.toarray()
# transforming a new document according to learn vocabulary
vectorizer.transform(['A new document.']).toarray()
