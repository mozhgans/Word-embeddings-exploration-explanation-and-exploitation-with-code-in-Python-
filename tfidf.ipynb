{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfidf.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwftFxMUPE_r"
      },
      "source": [
        "TF-IDF transforming\n",
        "The idea behind this approach is term weighting by exploitation of useful statistical measure called tf-idf. Having a large corpus of documents, words like ‘a’, ‘the’, ‘is’, etc. occur very frequently, but they don’t carry a lot of information. Using one-hot encoding approach we see that vectors of these words are not-so-sparse, claiming, that these words are important and carry a lot of information if being in so many documents. One of the ways to solve this problem is stopwords filtering, but this solution is discrete and not flexible to the domain zone we’re working with.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG6ziNSWDNuk"
      },
      "source": [
        "A native solution to the stopwords issue is using statistical quantity, which looks like:\n",
        "tfidf(term,doc)=tf(term,doc).idf(doc)\n",
        "The first part of it is tf, which means ‘term frequency’. By saying it we simply mean the number of times the word occurs in the document divided by the total number of words in the document:\n",
        "tf(term,doc)=(n_i)/sum(n_k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8-iOm5PDt7_"
      },
      "source": [
        "The second part is idf, which stands for ‘inverse document frequency’, interpreted like inversed number of documents, in which the term we’re interested in occurs. We’re also taking logarithm of this component:\n",
        "idf(term)=log(N/n_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpIpjZX2EtC0"
      },
      "source": [
        "in here, We’re taking the same CountVectorizer matrix calculated earlier and replacing each cell of it by tf-idf score for this term and this document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-E1SXImPDef",
        "outputId": "ac81bae6-bda7-4d13-fbfe-062173cc970f"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "corpus = ['this is the first document',\n",
        "           'this document is the second document',\n",
        "           'and this is the third one',\n",
        "           'is this the first document']\n",
        "print(corpus)\n",
        "vocabulary = ['this', 'document', 'first', 'is', 'second', 'the',\n",
        "               'and', 'one']\n",
        "\n",
        "print(vocabulary)\n",
        "pipe = Pipeline([('count', CountVectorizer(vocabulary=vocabulary)),\n",
        "                  ('tfid', TfidfTransformer())]).fit(corpus)\n",
        "pipe['count'].transform(corpus).toarray()\n",
        "#array([[1, 1, 1, 1, 0, 1, 0, 0],\n",
        "#       [1, 2, 0, 1, 1, 1, 0, 0],\n",
        "#       [1, 0, 0, 1, 0, 1, 1, 1],\n",
        "#       [1, 1, 1, 1, 0, 1, 0, 0]])\n",
        "pipe['tfid'].idf_\n",
        "#array([1.        , 1.22314355, 1.51082562, 1.        , 1.91629073,\n",
        "#       1.        , 1.91629073, 1.91629073])\n",
        "pipe.transform(corpus).shape\n",
        "#(4, 8)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this is the first document', 'this document is the second document', 'and this is the third one', 'is this the first document']\n",
            "['this', 'document', 'first', 'is', 'second', 'the', 'and', 'one']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}